# Example configuration without base model comparison
# Copy from configs/config.yaml and modify as needed

# Inference Configuration (for inference.py)
inference:
  prompts:
    - "A photo of sks dog"
    - "A photo of sks dog wearing a hat"
    - "sks dog running in the park"
  negative_prompt: "blurry, low quality"
  num_inference_steps: 30
  guidance_scale: 7.5
  num_images_per_prompt: 2
  height: 512
  width: 512
  generator_seed: 123
  output_dir: "inference_output"
  compare_with_base_model: false