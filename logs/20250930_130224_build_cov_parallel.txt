
================================================================================
NullBooth Script Execution Log
================================================================================
Script: build_cov_parallel
Start Time: 2025-09-30 13:02:24
Log File: logs/20250930_130224_build_cov_parallel.txt
================================================================================


üîç Logging started for 'build_cov_parallel' script
üìù Output will be saved to: logs/20250930_130224_build_cov_parallel.txt
--------------------------------------------------------------------------------
Process 3: Processing 3 timesteps
Process 3: Computing covariance matrices with streaming processing...
Process 3: Processing 1 timesteps √ó 64 layer/feature combinations
Process 3 timesteps:   0%|          | 0/1 [00:00<?, ?it/s]
Process 3 alpha_09_0939:   0%|          | 0/64 [00:00<?, ?it/s][A    Processing module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:   2%|1         | 1/64 [00:35<36:45, 35.01s/it][A    Processing module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:   3%|3         | 2/64 [02:08<1:11:48, 69.49s/it][A    Processing module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:   5%|4         | 3/64 [02:56<1:00:43, 59.73s/it][A    Processing module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:   6%|6         | 4/64 [03:00<37:33, 37.56s/it]  [A    Processing module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:   8%|7         | 5/64 [04:02<45:47, 46.56s/it][A    Processing module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:   9%|9         | 6/64 [05:00<48:38, 50.32s/it][A    Processing module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  11%|#         | 7/64 [05:57<50:01, 52.66s/it][A    Processing module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  12%|#2        | 8/64 [06:01<34:32, 37.02s/it][A    Processing module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  14%|#4        | 9/64 [06:59<39:52, 43.51s/it][A    Processing module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  16%|#5        | 10/64 [07:27<35:02, 38.94s/it][A    Processing module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  17%|#7        | 11/64 [08:08<34:54, 39.52s/it][A    Processing module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  19%|#8        | 12/64 [08:12<24:41, 28.49s/it][A    Processing module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  20%|##        | 13/64 [08:53<27:27, 32.31s/it][A    Processing module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  22%|##1       | 14/64 [09:39<30:24, 36.49s/it][A    Processing module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  23%|##3       | 15/64 [10:17<30:15, 37.04s/it][A    Processing module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  25%|##5       | 16/64 [10:21<21:33, 26.95s/it][A    Processing module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  27%|##6       | 17/64 [10:33<17:40, 22.57s/it][A    Processing module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  28%|##8       | 18/64 [10:44<14:39, 19.11s/it][A    Processing module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  30%|##9       | 19/64 [10:56<12:40, 16.90s/it][A    Processing module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  31%|###1      | 20/64 [10:59<09:21, 12.76s/it][A    Processing module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  33%|###2      | 21/64 [11:42<15:35, 21.76s/it][A    Processing module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  34%|###4      | 22/64 [11:51<12:39, 18.07s/it][A    Processing module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  36%|###5      | 23/64 [12:09<12:13, 17.89s/it][A    Processing module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  38%|###7      | 24/64 [12:12<09:03, 13.59s/it][A    Processing module.mid.block.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.mid.block.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  39%|###9      | 25/64 [12:17<07:07, 10.96s/it][A    Processing module.mid.block.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.mid.block.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  41%|####      | 26/64 [12:22<05:43,  9.05s/it][A    Processing module.mid.block.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.mid.block.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  42%|####2     | 27/64 [12:26<04:38,  7.54s/it][A    Processing module.mid.block.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.mid.block.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  44%|####3     | 28/64 [12:29<03:43,  6.21s/it][A    Processing module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  45%|####5     | 29/64 [13:16<10:45, 18.45s/it][A    Processing module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  47%|####6     | 30/64 [13:24<08:47, 15.52s/it][A    Processing module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  48%|####8     | 31/64 [13:38<08:08, 14.79s/it][A    Processing module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  50%|#####     | 32/64 [13:41<06:05, 11.41s/it][A    Processing module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  52%|#####1    | 33/64 [13:50<05:26, 10.54s/it][A    Processing module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  53%|#####3    | 34/64 [14:03<05:38, 11.29s/it][A    Processing module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  55%|#####4    | 35/64 [14:17<05:50, 12.09s/it][A    Processing module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  56%|#####6    | 36/64 [14:20<04:24,  9.43s/it][A    Processing module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  58%|#####7    | 37/64 [14:57<08:03, 17.90s/it][A    Processing module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  59%|#####9    | 38/64 [15:10<07:00, 16.18s/it][A    Processing module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  61%|######    | 39/64 [15:35<07:54, 18.98s/it][A    Processing module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  62%|######2   | 40/64 [15:39<05:47, 14.48s/it][A    Processing module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  64%|######4   | 41/64 [16:29<09:34, 24.99s/it][A    Processing module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  66%|######5   | 42/64 [16:47<08:28, 23.12s/it][A    Processing module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  67%|######7   | 43/64 [17:21<09:14, 26.42s/it][A    Processing module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  69%|######8   | 44/64 [17:25<06:30, 19.51s/it][A    Processing module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  70%|#######   | 45/64 [17:59<07:32, 23.81s/it][A    Processing module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  72%|#######1  | 46/64 [18:18<06:42, 22.36s/it][A    Processing module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  73%|#######3  | 47/64 [18:55<07:34, 26.74s/it][A    Processing module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  75%|#######5  | 48/64 [18:59<05:18, 19.91s/it][A    Processing module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  77%|#######6  | 49/64 [19:36<06:15, 25.05s/it][A    Processing module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  78%|#######8  | 50/64 [19:51<05:08, 22.05s/it][A    Processing module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  80%|#######9  | 51/64 [20:25<05:36, 25.87s/it][A    Processing module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  81%|########1 | 52/64 [20:29<03:50, 19.23s/it][A    Processing module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  83%|########2 | 53/64 [20:49<03:34, 19.53s/it][A    Processing module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  84%|########4 | 54/64 [21:24<04:01, 24.17s/it][A    Processing module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  86%|########5 | 55/64 [22:13<04:42, 31.38s/it][A    Processing module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  88%|########7 | 56/64 [22:16<03:04, 23.01s/it][A    Processing module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  89%|########9 | 57/64 [22:27<02:15, 19.34s/it][A    Processing module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  91%|######### | 58/64 [22:58<02:16, 22.73s/it][A    Processing module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  92%|#########2| 59/64 [23:45<02:30, 30.06s/it][A    Processing module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  94%|#########3| 60/64 [23:48<01:28, 22.08s/it][A    Processing module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  95%|#########5| 61/64 [23:59<00:56, 18.84s/it][A    Processing module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  97%|#########6| 62/64 [24:23<00:40, 20.21s/it][A    Processing module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939:  98%|#########8| 63/64 [25:10<00:28, 28.19s/it][A    Processing module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_09_0939/module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_09_0939: 100%|##########| 64/64 [25:13<00:00, 20.72s/it][A
                                                                        [AProcess 3 timesteps: 100%|##########| 1/1 [25:13<00:00, 1513.45s/it]                                                                    Process 3: ‚úÖ Timestep 939 completed and saved
Process 3: Computing covariance matrices with streaming processing...
Process 3: Processing 1 timesteps √ó 64 layer/feature combinations
Process 3 timesteps:   0%|          | 0/1 [00:00<?, ?it/s]
Process 3 alpha_10_0928:   0%|          | 0/64 [00:00<?, ?it/s][A    Processing module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:   2%|1         | 1/64 [01:24<1:28:32, 84.33s/it][A    Processing module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:   3%|3         | 2/64 [02:09<1:03:04, 61.03s/it][A    Processing module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:   5%|4         | 3/64 [03:01<57:59, 57.04s/it]  [A    Processing module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:   6%|6         | 4/64 [03:04<35:52, 35.88s/it][A    Processing module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:   8%|7         | 5/64 [04:17<48:17, 49.11s/it][A    Processing module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:   9%|9         | 6/64 [05:02<46:15, 47.86s/it][A    Processing module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  11%|#         | 7/64 [06:06<50:24, 53.06s/it][A    Processing module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  12%|#2        | 8/64 [06:09<34:43, 37.21s/it][A    Processing module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  14%|#4        | 9/64 [07:19<43:31, 47.48s/it][A    Processing module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  16%|#5        | 10/64 [07:36<34:01, 37.80s/it][A    Processing module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  17%|#7        | 11/64 [08:22<35:44, 40.46s/it][A    Processing module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  19%|#8        | 12/64 [08:25<25:18, 29.20s/it][A    Processing module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  20%|##        | 13/64 [09:30<34:02, 40.04s/it][A    Processing module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  22%|##1       | 14/64 [09:46<27:09, 32.59s/it][A    Processing module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  23%|##3       | 15/64 [10:21<27:09, 33.26s/it][A    Processing module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  25%|##5       | 16/64 [10:24<19:24, 24.25s/it][A    Processing module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  27%|##6       | 17/64 [10:41<17:18, 22.09s/it][A    Processing module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  28%|##8       | 18/64 [10:52<14:18, 18.67s/it][A    Processing module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  30%|##9       | 19/64 [11:03<12:18, 16.42s/it][A    Processing module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  31%|###1      | 20/64 [11:06<09:06, 12.43s/it][A    Processing module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  33%|###2      | 21/64 [12:04<18:35, 25.95s/it][A    Processing module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  34%|###4      | 22/64 [12:12<14:30, 20.73s/it][A    Processing module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  36%|###5      | 23/64 [12:29<13:18, 19.49s/it][A    Processing module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  38%|###7      | 24/64 [12:32<09:44, 14.62s/it][A    Processing module.mid.block.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.mid.block.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  39%|###9      | 25/64 [12:35<07:18, 11.23s/it][A    Processing module.mid.block.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.mid.block.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  41%|####      | 26/64 [12:38<05:29,  8.68s/it][A    Processing module.mid.block.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.mid.block.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  42%|####2     | 27/64 [12:42<04:26,  7.21s/it][A    Processing module.mid.block.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.mid.block.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  44%|####3     | 28/64 [12:45<03:35,  5.98s/it][A    Processing module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  45%|####5     | 29/64 [13:47<13:14, 22.71s/it][A    Processing module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  47%|####6     | 30/64 [13:55<10:24, 18.38s/it][A    Processing module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  48%|####8     | 31/64 [14:07<09:05, 16.52s/it][A    Processing module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  50%|#####     | 32/64 [14:11<06:47, 12.74s/it][A    Processing module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  52%|#####1    | 33/64 [14:17<05:36, 10.85s/it][A    Processing module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  53%|#####3    | 34/64 [14:30<05:39, 11.32s/it][A    Processing module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  55%|#####4    | 35/64 [14:42<05:35, 11.57s/it][A    Processing module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  56%|#####6    | 36/64 [14:45<04:13,  9.05s/it][A    Processing module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  58%|#####7    | 37/64 [15:14<06:42, 14.90s/it][A    Processing module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  59%|#####9    | 38/64 [15:27<06:15, 14.46s/it][A    Processing module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  61%|######    | 39/64 [15:48<06:52, 16.51s/it][A    Processing module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  62%|######2   | 40/64 [15:52<05:02, 12.59s/it][A    Processing module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  64%|######4   | 41/64 [16:09<05:22, 14.02s/it][A    Processing module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  66%|######5   | 42/64 [17:02<09:26, 25.75s/it][A    Processing module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  67%|######7   | 43/64 [17:36<09:52, 28.22s/it][A    Processing module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  69%|######8   | 44/64 [17:40<06:58, 20.92s/it][A    Processing module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  70%|#######   | 45/64 [17:51<05:38, 17.80s/it][A    Processing module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  72%|#######1  | 46/64 [18:40<08:09, 27.20s/it][A    Processing module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  73%|#######3  | 47/64 [19:14<08:18, 29.32s/it][A    Processing module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  75%|#######5  | 48/64 [19:21<05:58, 22.43s/it][A    Processing module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  77%|#######6  | 49/64 [19:36<05:05, 20.36s/it][A    Processing module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  78%|#######8  | 50/64 [20:19<06:21, 27.24s/it][A    Processing module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  80%|#######9  | 51/64 [20:53<06:20, 29.24s/it][A    Processing module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  81%|########1 | 52/64 [20:57<04:18, 21.51s/it][A    Processing module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  83%|########2 | 53/64 [21:05<03:12, 17.54s/it][A    Processing module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  84%|########4 | 54/64 [21:48<04:10, 25.03s/it][A    Processing module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  86%|########5 | 55/64 [22:37<04:50, 32.27s/it][A    Processing module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  88%|########7 | 56/64 [22:40<03:08, 23.61s/it][A    Processing module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  89%|########9 | 57/64 [22:47<02:09, 18.55s/it][A    Processing module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  91%|######### | 58/64 [23:26<02:28, 24.79s/it][A    Processing module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  92%|#########2| 59/64 [24:14<02:39, 31.83s/it][A    Processing module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  94%|#########3| 60/64 [24:18<01:33, 23.37s/it][A    Processing module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  95%|#########5| 61/64 [24:26<00:56, 18.69s/it][A    Processing module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  97%|#########6| 62/64 [24:57<00:44, 22.48s/it][A    Processing module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928:  98%|#########8| 63/64 [25:50<00:31, 31.70s/it][A    Processing module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_10_0928/module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_10_0928: 100%|##########| 64/64 [25:54<00:00, 23.19s/it][A
                                                                        [AProcess 3 timesteps: 100%|##########| 1/1 [25:54<00:00, 1554.21s/it]                                                                    Process 3: ‚úÖ Timestep 928 completed and saved
Process 3: Computing covariance matrices with streaming processing...
Process 3: Processing 1 timesteps √ó 64 layer/feature combinations
Process 3 timesteps:   0%|          | 0/1 [00:00<?, ?it/s]
Process 3 alpha_11_0916:   0%|          | 0/64 [00:00<?, ?it/s][A    Processing module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:   2%|1         | 1/64 [00:11<11:52, 11.31s/it][A    Processing module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:   3%|3         | 2/64 [02:07<1:15:21, 72.92s/it][A    Processing module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:   5%|4         | 3/64 [03:03<1:06:21, 65.28s/it][A    Processing module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.0.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:   6%|6         | 4/64 [03:07<40:53, 40.89s/it]  [A    Processing module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:   8%|7         | 5/64 [03:22<31:07, 31.66s/it][A    Processing module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:   9%|9         | 6/64 [05:13<56:49, 58.79s/it][A    Processing module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  11%|#         | 7/64 [06:18<57:43, 60.76s/it][A    Processing module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.0.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  12%|#2        | 8/64 [06:29<41:57, 44.96s/it][A    Processing module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  14%|#4        | 9/64 [07:38<47:58, 52.34s/it][A    Processing module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  16%|#5        | 10/64 [08:02<39:14, 43.60s/it][A    Processing module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  17%|#7        | 11/64 [08:37<36:14, 41.03s/it][A    Processing module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.1.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  19%|#8        | 12/64 [08:41<25:46, 29.74s/it][A    Processing module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  20%|##        | 13/64 [09:43<33:41, 39.64s/it][A    Processing module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  22%|##1       | 14/64 [10:04<28:12, 33.86s/it][A    Processing module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  23%|##3       | 15/64 [10:35<27:05, 33.17s/it][A    Processing module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.1.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  25%|##5       | 16/64 [10:39<19:20, 24.18s/it][A    Processing module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  27%|##6       | 17/64 [10:55<17:09, 21.90s/it][A    Processing module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  28%|##8       | 18/64 [11:09<14:49, 19.34s/it][A    Processing module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  30%|##9       | 19/64 [11:21<12:48, 17.08s/it][A    Processing module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.2.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  31%|###1      | 20/64 [11:24<09:29, 12.95s/it][A    Processing module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  33%|###2      | 21/64 [12:14<17:15, 24.08s/it][A    Processing module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  34%|###4      | 22/64 [12:24<14:01, 20.04s/it][A    Processing module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  36%|###5      | 23/64 [12:43<13:23, 19.59s/it][A    Processing module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.down.blocks.2.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  38%|###7      | 24/64 [12:47<09:53, 14.83s/it][A    Processing module.mid.block.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.mid.block.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  39%|###9      | 25/64 [12:54<08:03, 12.41s/it][A    Processing module.mid.block.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.mid.block.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  41%|####      | 26/64 [12:59<06:37, 10.47s/it][A    Processing module.mid.block.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.mid.block.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  42%|####2     | 27/64 [13:04<05:23,  8.75s/it][A    Processing module.mid.block.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.mid.block.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  44%|####3     | 28/64 [13:08<04:16,  7.11s/it][A    Processing module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  45%|####5     | 29/64 [13:57<11:38, 19.94s/it][A    Processing module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  47%|####6     | 30/64 [14:08<09:40, 17.07s/it][A    Processing module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  48%|####8     | 31/64 [14:23<09:07, 16.58s/it][A    Processing module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.1.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  50%|#####     | 32/64 [14:27<06:47, 12.73s/it][A    Processing module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  52%|#####1    | 33/64 [14:39<06:24, 12.39s/it][A    Processing module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  53%|#####3    | 34/64 [14:49<05:53, 11.79s/it][A    Processing module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  55%|#####4    | 35/64 [15:06<06:24, 13.26s/it][A    Processing module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.1.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  56%|#####6    | 36/64 [15:09<04:50, 10.38s/it][A    Processing module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  58%|#####7    | 37/64 [15:48<08:31, 18.93s/it][A    Processing module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/out: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  59%|#####9    | 38/64 [16:02<07:34, 17.48s/it][A    Processing module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/q: cov_shape=(1280, 1280) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  61%|######    | 39/64 [16:22<07:36, 18.27s/it][A    Processing module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.1.attentions.2.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  62%|######2   | 40/64 [16:26<05:35, 13.99s/it][A    Processing module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  64%|######4   | 41/64 [17:13<09:08, 23.84s/it][A    Processing module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  66%|######5   | 42/64 [17:34<08:27, 23.06s/it][A    Processing module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  67%|######7   | 43/64 [18:07<09:01, 25.80s/it][A    Processing module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.2.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  69%|######8   | 44/64 [18:10<06:22, 19.13s/it][A    Processing module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  70%|#######   | 45/64 [18:50<08:00, 25.28s/it][A    Processing module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  72%|#######1  | 46/64 [19:07<06:52, 22.91s/it][A    Processing module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  73%|#######3  | 47/64 [19:38<07:09, 25.25s/it][A    Processing module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.2.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  75%|#######5  | 48/64 [19:41<04:58, 18.68s/it][A    Processing module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  77%|#######6  | 49/64 [20:17<05:59, 23.93s/it][A    Processing module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/out: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  78%|#######8  | 50/64 [20:36<05:10, 22.17s/it][A    Processing module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/q: cov_shape=(640, 640) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  80%|#######9  | 51/64 [21:03<05:10, 23.91s/it][A    Processing module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.2.attentions.2.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  81%|########1 | 52/64 [21:07<03:32, 17.74s/it][A    Processing module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  83%|########2 | 53/64 [21:27<03:23, 18.53s/it][A    Processing module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  84%|########4 | 54/64 [21:59<03:44, 22.41s/it][A    Processing module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  86%|########5 | 55/64 [22:47<04:32, 30.25s/it][A    Processing module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.3.attentions.0.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  88%|########7 | 56/64 [22:51<02:57, 22.19s/it][A    Processing module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  89%|########9 | 57/64 [23:04<02:17, 19.63s/it][A    Processing module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  91%|######### | 58/64 [23:33<02:14, 22.47s/it][A    Processing module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  92%|#########2| 59/64 [24:21<02:30, 30.10s/it][A    Processing module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.3.attentions.1.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  94%|#########3| 60/64 [24:25<01:28, 22.11s/it][A    Processing module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/k: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/k: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  95%|#########5| 61/64 [24:35<00:56, 18.69s/it][A    Processing module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/out: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/out: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  97%|#########6| 62/64 [24:59<00:40, 20.25s/it][A    Processing module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/q: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/q: cov_shape=(320, 320) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916:  98%|#########8| 63/64 [25:46<00:28, 28.22s/it][A    Processing module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/v: 1000 samples (batch_size=800)
Process 3: alpha_11_0916/module.up.blocks.3.attentions.2.transformer.blocks.0.attn2/v: cov_shape=(768, 768) (K‚ÇÄK‚ÇÄ·µÄ only, no SVD)

Process 3 alpha_11_0916: 100%|##########| 64/64 [25:50<00:00, 20.77s/it][A
                                                                        [AProcess 3 timesteps: 100%|##########| 1/1 [25:50<00:00, 1550.04s/it]                                                                    Process 3: ‚úÖ Timestep 916 completed and saved

--------------------------------------------------------------------------------
Script execution completed: 2025-09-30 15:25:56
Log saved to: logs/20250930_130224_build_cov_parallel.txt
================================================================================

